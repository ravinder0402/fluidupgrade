name: Upgrading fluid using helm

on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: self-hosted

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up kubeconfig
        run: |
          echo "${{ secrets.KUBECONFIG_RAW }}" > kubeconfig
          export KUBECONFIG=$PWD/kubeconfig
          kubectl config get-contexts

      - name: Install AWS CLI
        run: |
          sudo apt update
          sudo apt install -y awscli

      - name: Configure AWS CLI for MinIO
        run: |
          mkdir -p ~/.aws
          cat <<EOF > ~/.aws/credentials
          [default]
          aws_access_key_id = ${{ secrets.MINIO_ACCESS_KEY }}
          aws_secret_access_key = ${{ secrets.MINIO_SECRET_KEY }}
          EOF

          cat <<EOF > ~/.aws/config
          [default]
          region = us-east-1
          output = json
          EOF

      - name: Backup CCS PostgreSQL and upload to MinIO
        run: |
          TIMESTAMP=$(date +%Y%m%d%H%M%S)
          FILE="ccs_pg_backup_$TIMESTAMP.sql"
          kubectl exec -it -n fluid ccs-postgresql-cluster-0 -- pg_dumpall -U postgres > $FILE
          aws --endpoint-url ${{ secrets.MINIO_ENDPOINT }} s3 cp $FILE s3://${{ secrets.MINIO_BUCKET }}/$FILE
          rm $FILE

          
      - name: Backup Keycloak PostgreSQL  and upload to MinIO
        run: |
          TIMESTAMP=$(date +%Y%m%d%H%M%S)
          FILE="keycloak_pg_backup_$TIMESTAMP.sql"
          kubectl exec -it -n fluid keycloak-postgresql-cluster-0 -- \
            pg_dumpall -U postgres > $FILE
          aws --endpoint-url ${{ secrets.MINIO_ENDPOINT }} s3 cp $FILE s3://${{ secrets.MINIO_BUCKET }}/$FILE
          rm $FILE
          
      - name: Backup Keycloak PostgreSQL cluster and upload to MinIO(corobots)
        run: |
          TIMESTAMP=$(date +%Y%m%d%H%M%S)
          FILE="corobots_all_databases_backup_$TIMESTAMP.sql"
          kubectl exec -n corobots keycloak-pg-0 -- bash -c "pg_dumpall -U root" > $FILE
          aws --endpoint-url ${{ secrets.MINIO_ENDPOINT }} s3 cp $FILE s3://${{ secrets.MINIO_BUCKET }}/$FILE
          rm $FILE
          
      - name: Backup all MongoDB databases and upload to MinIO (Config-db)
        run: |
          TIMESTAMP=$(date +%Y%m%d%H%M%S)
          FILE="config-db_all_dbs_backup_$TIMESTAMP.archive"
          kubectl exec -it -n fluid configdb-0 -- \
            mongodump --username sigma --password "${{ secrets.MONGO_PASSWORD }}" --authenticationDatabase admin --archive > $FILE
          aws --endpoint-url ${{ secrets.MINIO_ENDPOINT }} s3 cp $FILE s3://${{ secrets.MINIO_BUCKET }}/$FILE
          rm $FILE
          
      - name: Backup all MongoDB databases and upload to MinIO (Metrics-db)
        run: |
          TIMESTAMP=$(date +%Y%m%d%H%M%S)
          FILE="metrics-db_all_dbs_backup_$TIMESTAMP.archive"
          kubectl exec -it -n fluid metricsdb-0 -- \
            mongodump --username sigma --password "${{ secrets.MONGO_PASSWORD }}" --authenticationDatabase admin --archive > $FILE
          aws --endpoint-url ${{ secrets.MINIO_ENDPOINT }} s3 cp $FILE s3://${{ secrets.MINIO_BUCKET }}/$FILE
          rm $FILE

      - name: Backup all MongoDB databases and upload to MinIO (Config-db-Corobots)
        run: |
          TIMESTAMP=$(date +%Y%m%d%H%M%S)
          FILE="corobots_config-db_all_dbs_backup_$TIMESTAMP.archive"
          kubectl exec -it -n corobots configdb-0 -- \
            mongodump --username sigma --password "${{ secrets.MONGO_PASSWORD }}" --authenticationDatabase admin --archive > $FILE
          aws --endpoint-url ${{ secrets.MINIO_ENDPOINT }} s3 cp $FILE s3://${{ secrets.MINIO_BUCKET }}/$FILE
          rm $FILE
          
      - name: Backup all MongoDB databases and upload to MinIO (Metrics-db-Corobots)
        run: |
          TIMESTAMP=$(date +%Y%m%d%H%M%S)
          FILE="corobots_metrics-db_all_dbs_backup_$TIMESTAMP.archive"
          kubectl exec -it -n corobots metricsdb-0 -- \
            mongodump --username sigma --password "${{ secrets.MONGO_PASSWORD }}" --authenticationDatabase admin --archive > $FILE
          aws --endpoint-url ${{ secrets.MINIO_ENDPOINT }} s3 cp $FILE s3://${{ secrets.MINIO_BUCKET }}/$FILE
          rm $FILE

      - name: Backup values.yaml and upload to MinIO
        working-directory: ./helm
        run: |
          TIMESTAMP=$(date +%Y%m%d%H%M%S)
          FILE="values.yaml.$TIMESTAMP"
          cp values.yaml $FILE
          aws --endpoint-url ${{ secrets.MINIO_ENDPOINT }} s3 cp $FILE s3://${{ secrets.MINIO_BUCKET }}/$FILE
          rm $FILE

      - name: Helm registry login
        run: |
          helm registry login docker.io -u ${{ secrets.DOCKER_USERNAME }} -p ${{ secrets.DOCKER_PASSWORD }}

      - name: Helm dependency build
        working-directory: ./helm
        run: helm dependency build

      - name: Helm upgrade/install fluid chart
        working-directory: ./helm
        run: |
          helm upgrade --install fluid . -f values.yaml -n fluid --create-namespace
          helm list -A
          
      - name: Restoring CCS postgresql backup
        env:
          MINIO_ENDPOINT: ${{ secrets.MINIO_ENDPOINT }}
          MINIO_BUCKET: ${{ secrets.MINIO_BUCKET }}
          AWS_ACCESS_KEY_ID: ${{ secrets.MINIO_ACCESS_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.MINIO_SECRET_KEY }}
        run: |
          echo "MINIO_ENDPOINT=$MINIO_ENDPOINT"
          echo "MINIO_BUCKET=$MINIO_BUCKET"
          echo "Restoring CCS PostgreSQL backup..."
      
          # Find the latest backup file in MinIO
          FILE=$(aws --endpoint-url "$MINIO_ENDPOINT" s3 ls "s3://$MINIO_BUCKET/" | grep ccs_pg_backup_ | sort | tail -n1 | awk '{print $4}')
          echo "Downloading backup file $FILE from MinIO"
          aws --endpoint-url "$MINIO_ENDPOINT" s3 cp "s3://$MINIO_BUCKET/$FILE" .
      
          # Terminate connections and drop databases inside the pod
          kubectl exec -i ccs-postgresql-cluster-0 -n fluid -- bash -c "
          psql -U postgres -d postgres <<EOF
          SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'audit-db';
          SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'cloud';
          SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'ccs_postgresql_cluster';
          \\! psql -U postgres -d postgres -c \"DROP DATABASE IF EXISTS \\\"audit-db\\\";\"
          \\! psql -U postgres -d postgres -c \"DROP DATABASE IF EXISTS cloud;\"
          \\! psql -U postgres -d postgres -c \"DROP DATABASE IF EXISTS ccs_postgresql_cluster;\"
          EOF
          "
      
          # Restore from the downloaded backup file
          kubectl exec -i ccs-postgresql-cluster-0 -n fluid -- psql -U postgres < "$FILE"
          rm "$FILE"
          echo "CCS PostgreSQL restore complete."
