---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: etcd-backup
  namespace: kube-system
spec:
  accessModes:
    - ReadWriteOnce
  volumeMode: Filesystem
  resources:
    requests:
      storage: 50Gi
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: etcd-backup
  namespace: kube-system
spec:
  concurrencyPolicy: Allow
  failedJobsHistoryLimit: 1
  jobTemplate:
    spec:
      template:
        spec:
          # hostAliases:       
          # - ip: "192.168.100.86"
          #   hostnames:
          #   - "minio.coredge.io"
          containers:
          - args:
              - -ec
              # the script wait untill the snapshot file is available
              # then upload to s3
              # for folks using non-aws S3 like IBM Cloud Object Storage service, add a `--endpoint-url` option
              # run `aws --endpoint-url <https://your_s3_endpoint> s3 cp ...`
              # change the s3://<path> to your desired location
              - |
                # set variables for filename
                cd /backups
                filename=$(ls *.db | tail -n 1)
          
                # Upload file to S3 bucket
                /s5cmd  cp ${filename} s3://$S3_BUCKET/$S3_PREFIX/etcd/${filename}              
                
                # List all files in the bucket
                file_list=$(/s5cmd ls s3://$S3_BUCKET/$S3_PREFIX/etcd/ | awk '{print $NF}')
                
                # Count the number of files in the bucket
                file_count=$(echo "${file_list}" | wc -l)
                
                # If there are more than RETAIN_COUNT files, delete the oldest ones
                if [ "${file_count}" -gt "$RETAIN_COUNT" ]; then
                  files_to_delete=$((file_count - $RETAIN_COUNT))
                  echo "Deleting ${files_to_delete} old files..."
                  echo "${file_list}" | head -n "${files_to_delete}" | while read -r file; do
                    echo $ {file}
                    /s5cmd rm "s3://$S3_BUCKET/$S3_PREFIX/etcd/${file}"
                  done
                fi
                
                #If there are more than RETAIN_COUNT files, delete the oldest ones for pv
                find /backups/* -mtime +3 -exec rm -f {} \; 2> /dev/null                 
                
            command:
            - /bin/sh
            env:
            - name: S3_PREFIX
              valueFrom:
                secretKeyRef:
                  name: s3-credentials
                  key: S3_PREFIX              
            - name: RETAIN_COUNT
              value: "12"
            - name: S3_BUCKET
              valueFrom:
                secretKeyRef:
                  name: s3-credentials
                  key: S3_BUCKET
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: s3-credentials
                  key: AWS_ACCESS_KEY_ID
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: s3-credentials
                  key: AWS_SECRET_ACCESS_KEY
            - name: S3_ENDPOINT_URL
              valueFrom:
                secretKeyRef:
                  name: s3-credentials
                  key: S3_ENDPOINT_URL
            image: peakcom/s5cmd 
            imagePullPolicy: IfNotPresent
            name: upload
            volumeMounts:
            - mountPath: /backups
              name: backup        
          initContainers:
          - name: backup
            args:
            - -c
            - etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt
              --cert=/etc/kubernetes/pki/etcd/healthcheck-client.crt --key=/etc/kubernetes/pki/etcd/healthcheck-client.key
              snapshot save /backup/etcd-snapshot-$(printf "%(%Y-%m-%d_%H:%M:%S_%Z)T\n").db
            command:
            - /bin/sh
            env:
            - name: ETCDCTL_API
              value: "3"
            image: docker.io/coredgeio/etcd:3.5.9-0
            imagePullPolicy: IfNotPresent
            resources: {}
            terminationMessagePath: /dev/termination-log
            terminationMessagePolicy: File
            volumeMounts:
            - mountPath: /etc/kubernetes/pki/etcd
              name: etcd-certs
              readOnly: true
            - mountPath: /backup
              name: backup
          dnsPolicy: ClusterFirst
          hostNetwork: true
          nodeSelector:
            node-role.kubernetes.io/control-plane: ""
          restartPolicy: OnFailure
          schedulerName: default-scheduler
          securityContext: {}
          terminationGracePeriodSeconds: 30
          tolerations:
          - effect: NoSchedule
            operator: Exists
          volumes:
          - hostPath:
              path: /etc/kubernetes/pki/etcd
              type: DirectoryOrCreate
            name: etcd-certs
          - name: backup
            persistentVolumeClaim:
              claimName: etcd-backup
  schedule: "0 */6 * * *"
  successfulJobsHistoryLimit: 3
  suspend: false
